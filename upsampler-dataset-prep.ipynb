{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jukebox conda environment is required for this notebook to run\n",
    "\n",
    "# mp3 support\n",
    "!conda install -c conda-forge ffmpeg --yes \n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import librosa as l\n",
    "import torch as t\n",
    "import soundfile as sf\n",
    "\n",
    "from jukebox.make_models import make_vqvae \n",
    "from jukebox.hparams import Hyperparams, setup_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = r'e:\\ML\\jukebox-upsampling-dataset'\n",
    "\n",
    "folders = [\n",
    "    r'c:\\Music\\Artist\\Album',\n",
    "    r'c:\\Music\\Artist2\\Album2',\n",
    "]\n",
    "\n",
    "sr = 44100\n",
    "chunk_length_in_seconds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_vqvae(chunk_length, sr):\n",
    "    hps = Hyperparams(\n",
    "        levels=3, \n",
    "        sample_length=chunk_length, \n",
    "        sr=sr,\n",
    "        n_samples=1,\n",
    "        hop_fraction=[0.5,0.5,0.125])\n",
    "\n",
    "    return make_vqvae(setup_hparams('vqvae', \n",
    "                       dict(sample_length=hps.get('sample_length', 0), \n",
    "                            sample_length_in_seconds=hps.get('sample_length_in_seconds', 0))), 'cuda')\n",
    "\n",
    "def process(folders, output_path, chunk_length_in_seconds, sr):\n",
    "    counter = 0\n",
    "    \n",
    "    chunk_length = 128 * (sr * chunk_length_in_seconds // 128) # chunk size is rounded down to be multiple of 128\n",
    "\n",
    "    vqvae = setup_vqvae(chunk_length, sr).cuda()\n",
    "    \n",
    "    for f in folders:\n",
    "        for track in os.listdir(f):\n",
    "            if any(ext in track for ext in ['.wav', '.flac', '.mp3']):\n",
    "                fullPath = os.path.join(f, track)\n",
    "                \n",
    "                print(fullPath)\n",
    "                \n",
    "                y, _ = l.load(fullPath, sr = sr)\n",
    "\n",
    "                y = l.util.normalize(y)\n",
    "\n",
    "                for i in range(chunk_length, len(y), chunk_length):\n",
    "                    chunk = y[i - chunk_length:i]\n",
    "                    \n",
    "                    sf.write(os.path.join(output_path, f'%06d.wav' % counter), chunk, sr, 'PCM_24')\n",
    "                    \n",
    "                    x = t.tensor(chunk).unsqueeze(0).unsqueeze(2).cuda()\n",
    "                    zs = vqvae.encode(x, start_level=2)\n",
    "                    emb = vqvae.bottleneck.decode(zs, start_level=2, end_level=None)\n",
    "\n",
    "                    np.save(os.path.join(output_path, f'%06d.emb' % counter), emb[0].squeeze(0).cpu().detach().numpy())\n",
    "\n",
    "                    counter += 1\n",
    "                    \n",
    "process(folders, output_path, chunk_length_in_seconds, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
